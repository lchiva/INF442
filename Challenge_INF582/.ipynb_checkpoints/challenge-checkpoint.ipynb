{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92f271b",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c513641",
   "metadata": {},
   "source": [
    "Getting State-of-the-Art results on sequence classification\n",
    "In order to get State-of-the-Art results on this task, we will fine-tune our models on a given dataset. Fine-tuning a model means that we will slightly train it on top of an already trained checkpoint. The learning rate will be very low, as having it to high would result in catastrophic forgetting -> the model would forget what it had learned until now semantically and syntaxically.\n",
    "We will follow the procedure detailed below:\n",
    "\n",
    "- Installing required dependencies\n",
    "- Loading both Fake and Real news data\n",
    "- Preprocess the text - Data Cleaning & Standardisation\n",
    "- Initiatizing pretrained models - BERT & RoBERTa\n",
    "- Tokenzie this dataset so that it can be used by the model\n",
    "- Train and Test split\n",
    "- Set-up a training loop; train the model on the training data\n",
    "- Evaluate the model on the testing data by comparing to the actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b80873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 13:55:15.029060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "from uuid import uuid4\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "## Torch Modules\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "## Transformer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import (BertForSequenceClassification, TFBertForSequenceClassification, \n",
    "                        BertTokenizer,\n",
    "                        TFRobertaForSequenceClassification,\n",
    "                        RobertaForSequenceClassification,\n",
    "                        RobertaTokenizer,\n",
    "                         AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aadde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device \n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8aa70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
